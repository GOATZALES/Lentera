# Lentera/ai_service/client.py
from django.conf import settings
import logging
from langchain_google_genai import ChatGoogleGenerativeAI
# from langchain_openai import ChatOpenAI # Jika pakai OpenAI
import google.generativeai as genai # Untuk pemanggilan non-langchain jika masih ada

logger = logging.getLogger(__name__)

# --- Konfigurasi untuk Pemanggilan Langsung (non-Langchain) ---
if hasattr(settings, 'GOOGLE_API_KEY') and settings.GOOGLE_API_KEY:
    try:
        genai.configure(api_key=settings.GOOGLE_API_KEY)
        logger.info("Google Generative AI (Direct Call) configured successfully.")
    except Exception as e:
        logger.error(f"Error configuring Google Generative AI (Direct Call): {e}", exc_info=True)
else:
    logger.warning("GOOGLE_API_KEY not found. Direct Google AI services may not function.")

def get_gemini_text_response(prompt_text: str, model_name: str = "gemini-1.5-flash-latest"):
    """
    Mendapatkan respons teks dari model Gemini (pemanggilan langsung).
    """
    if not (hasattr(settings, 'GOOGLE_API_KEY') and settings.GOOGLE_API_KEY):
        logger.error("Google API key (for Gemini direct call) not configured.")
        return {"error": "AI service (direct call) not configured.", "status_code": 503}
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt_text)
        if response.parts:
            logger.debug(f"Gemini direct raw response text: {response.text[:200]}...")
            return response.text
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
            block_reason_message = response.prompt_feedback.block_reason_message or "Unknown block reason"
            logger.warning(f"Gemini direct request blocked. Reason: {block_reason_message}")
            return {"error": f"Request blocked by AI (direct). Reason: {block_reason_message}", "status_code": 403}
        else:
            candidate_info = "No parts or specific block reason found (direct)."
            if response.candidates:
                candidate_info = f"Finish reason: {response.candidates[0].finish_reason}. Safety ratings: {response.candidates[0].safety_ratings}"
            logger.warning(f"Gemini direct response did not contain parts. Candidate info: {candidate_info}")
            return {"error": f"No content generated by AI (direct). Details: {candidate_info}", "status_code": 500}
    except Exception as e:
        error_message = str(e)
        logger.error(f"Google Generative AI (direct call) API error: {error_message}", exc_info=True)
        return {"error": f"Error communicating with AI service (direct): {error_message}", "status_code": 500}

# --- Konfigurasi untuk Langchain ---
def get_langchain_gemini_llm(model_name: str = "gemini-1.5-flash-latest", temperature: float = 0.5):
    if not (hasattr(settings, 'GOOGLE_API_KEY') and settings.GOOGLE_API_KEY):
        logger.error("Google API key (for Gemini Langchain) not configured.")
        raise ValueError("Google API Key for Langchain not configured.")
    
    try:
        llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=settings.GOOGLE_API_KEY,
            temperature=temperature,
            convert_system_message_to_human=True 
        )
        logger.info(f"Langchain Gemini LLM ({model_name}) initialized.")
        return llm
    except Exception as e:
        logger.error(f"Failed to initialize Langchain Gemini LLM: {e}", exc_info=True)
        raise